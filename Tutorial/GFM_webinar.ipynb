{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7e8495-eaa4-49f3-8ba4-5ee1119dbfac",
   "metadata": {},
   "source": [
    "![ThinkOnward Logo](assets/ThinkOnward.png)\n",
    "# The Geophysical Foundation Model\n",
    "#### Jesse Pisel and Jeff Roth, November 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbf0d5b-4b57-47e1-81ef-3b17c1daa94f",
   "metadata": {},
   "source": [
    "Make sure you install the required packages from `requirements.txt` as outlined in the `README` file in the repository root directory.\n",
    "\n",
    "First you need to import packages needed for data wrangling and inference. You also need to add the current path to the system path so you can import the GFM architecture later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c2c699-d21a-4b0d-b993-90ecac441006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.transform as st\n",
    "import torch\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f12a3b-6e83-4640-b7ae-a3390893a208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the geophysical-foundation-model directory to system path for later\n",
    "current_dir = os.path.abspath(os.path.dirname('..'))\n",
    "project_root = os.path.dirname(current_dir)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53909a6-225d-45c7-acbd-6cc0db71e031",
   "metadata": {},
   "source": [
    "To download the data and the model you will need a [HuggingFace](https://huggingface.co) account and [request model access](https://huggingface.co/thinkonward/geophysical-foundation-model)\n",
    "\n",
    "<img src=\"assets/model_card.png\" alt=\"huggingface model card\" width=\"800\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70a81f0-866a-4b77-8bd8-619c4d8b997e",
   "metadata": {},
   "source": [
    "After requesting access, you need to [set up an access token](https://huggingface.co/docs/hub/security-tokens) to use the `huggingface_hub` package. Once that is set up, log in by running the next cell and entering your token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e32c6-ce58-4a39-b278-6d416b83233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login, hf_hub_download, snapshot_download\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17653cb-eab4-42f1-85fc-8f4b39ad014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_REPO_ID = \"thinkonward/patch-the-planet\"\n",
    "DATA_FILENAME = \"data/seismicCubes_RFC_fullstack_2023_66442858.parquet\"\n",
    "MODEL_REPO_ID = \"thinkonward/geophysical-foundation-model\"\n",
    "\n",
    "hf_hub_download(\n",
    "    repo_id=DATA_REPO_ID,\n",
    "    filename=DATA_FILENAME,\n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=\"./dataset\",\n",
    ")\n",
    "snapshot_download(repo_id=MODEL_REPO_ID, repo_type=\"model\", local_dir=\"./gfm-weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3ac32b-ef24-40da-8298-4617b423421e",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "Define some functions to convert the seismic volume from parquet to numpy array and mask out a portion we want to interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216dd3d1-9dfd-4885-85ea-9d6a35abab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parquet2array(parquet_file, original_shape=(300, 300, 1259)):\n",
    "    df = pd.read_parquet(parquet_file)\n",
    "    data_only = df.drop(columns=[\"Row\", \"Col\"])\n",
    "    # Convert the DataFrame back to a 2D numpy array\n",
    "    reshaped_array = data_only.values\n",
    "    # Reshape the 2D array back into a 3D array\n",
    "    array = reshaped_array.reshape(original_shape)\n",
    "    return array\n",
    "\n",
    "\n",
    "def mask_image(seismic_slice):\n",
    "    masked_file = seismic_slice.copy()\n",
    "    # the masked chunk is hard coded here\n",
    "    masked_file[:, 40:110] = 122\n",
    "    mask = np.where(masked_file == 122.0, 1, 0)\n",
    "    return masked_file, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f7af95-36a3-4c9c-b7e8-c037b2d0aa14",
   "metadata": {},
   "source": [
    "Visualize the selected line from the volume and see what the model is going to interpolate and the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9f7d13-d338-41bd-9a4b-a4dfcdf3301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEIS_VOL = parquet2array(\n",
    "    \"./dataset/data/seismicCubes_RFC_fullstack_2023_66442858.parquet\"\n",
    ")\n",
    "SEISMIC_SLICE = SEIS_VOL.T[:, :, 10]\n",
    "MASKED_SLICE, MASK = mask_image(SEISMIC_SLICE)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(6, 6))\n",
    "ax[0].imshow(MASKED_SLICE, cmap=\"gray\")\n",
    "ax[0].set_title(\"Seismic\")\n",
    "ax[1].imshow(MASK, cmap=\"gray\")\n",
    "ax[1].set_title(\"Mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8699a896-066e-4360-a65f-511192994f1d",
   "metadata": {},
   "source": [
    "## Instantiate the model\n",
    "Create an instance of the model architecture, then load the downloaded weights using the `from_pretrained` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8850e9-d72d-4210-aa4e-fb0a8f47ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GFM import ElasticViTMAE\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ElasticViTMAE.ElasticViTMAE()\n",
    "model = model.from_pretrained(\"./gfm-weights\")\n",
    "model = model.float()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0510b15f-733a-4881-901b-55484edc97be",
   "metadata": {},
   "source": [
    "## Do some interpolation\n",
    "Now the fun part!\n",
    "1. resize the seismic slice and mask to the shape for the model to ingest\n",
    "2. get the number of visible patches\n",
    "3. run inference\n",
    "4. combine the prediction and visible portions\n",
    "5. visualize it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a6d211-03b1-488a-80dc-97be059da85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare seismic slice (seismic_slice: 2D slice of volume)\n",
    "resized_slice = st.resize(\n",
    "    MASKED_SLICE.T,\n",
    "    model.patch_embed.img_size[::-1],\n",
    "    order=3,\n",
    "    anti_aliasing=True,\n",
    "    preserve_range=True,\n",
    ")\n",
    "resized_slice = resized_slice.T.astype(np.float32)\n",
    "resized_slice = (resized_slice - SEIS_VOL.mean()) / SEIS_VOL.std()\n",
    "x = torch.tensor(resized_slice)\n",
    "x = x.unsqueeze(0)  # add channel dim\n",
    "x = x.unsqueeze(0)  # add batch dim\n",
    "x = x.float()\n",
    "x = x.to(device)\n",
    "\n",
    "# Prepare mask (target_mask_slice: 2D slice of mask)\n",
    "resized_mask = st.resize(\n",
    "    MASK, model.patch_embed.img_size, order=0, preserve_range=True\n",
    ")\n",
    "mask_idx = np.flatnonzero(resized_mask[0, :])\n",
    "input_mask = np.zeros(model.patch_embed.grid_size)\n",
    "input_mask[:, mask_idx[0] : mask_idx[-1] + 1] = 1\n",
    "input_mask = torch.tensor(input_mask)\n",
    "input_mask = input_mask.float()\n",
    "input_mask = input_mask.to(device)\n",
    "\n",
    "# Prepare length of visible patches\n",
    "len_keep = torch.tensor(int(input_mask.shape[1] - input_mask.sum()))\n",
    "len_keep = len_keep.to(device)\n",
    "\n",
    "# Get interpolated slice\n",
    "loss, pred, mask = model(x, input_mask, len_keep)\n",
    "\n",
    "# Combine prediction and visible part to generate output\n",
    "mask = mask.unsqueeze(-1)\n",
    "visible = model.patchify(x)\n",
    "combined_pred = pred * mask + visible * (1 - mask)\n",
    "combined_pred = model.unpatchify(combined_pred)\n",
    "combined_pred = combined_pred.cpu().detach().numpy()\n",
    "combined_pred = combined_pred.reshape(model.patch_embed.img_size)\n",
    "combined_pred = combined_pred * SEIS_VOL.std() + SEIS_VOL.mean()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.imshow(combined_pred, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36d50be-4e22-4694-ba48-28e90d7c9b17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
