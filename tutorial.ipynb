{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7e8495-eaa4-49f3-8ba4-5ee1119dbfac",
   "metadata": {},
   "source": [
    "![ThinkOnward Logo](src_imgs/ThinkOnward.png)\n",
    "# The Geophysical Foundation Model\n",
    "#### Jesse Pisel and Jeff Roth, November 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28543373-5145-4ba9-b129-1f558c26b5ce",
   "metadata": {},
   "source": [
    "## Downloads and packages\n",
    "Start by:\n",
    "* installing packages\n",
    "* creating a dataset directory\n",
    "* clone the `geophysical-foundation-model` repository from GitHub\n",
    "* rename the repo to `GFM`\n",
    "* change the repo into a Python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4efa46-f3e6-4ae5-9f29-b4b303e2f2f9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "! pip install huggingface_hub timm scikit-image\n",
    "# torch version that matches your machine too\n",
    "! mkdir -p dataset\n",
    "! git clone https://github.com/thinkonward/geophysical-foundation-model.git\n",
    "! mv geophysical-foundation-model GFM && cd GFM && touch __init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ee2720-0b11-4b1c-981b-eae465900733",
   "metadata": {},
   "source": [
    "Import packages needed for data wrangling and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c2c699-d21a-4b0d-b993-90ecac441006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.transform as st\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53909a6-225d-45c7-acbd-6cc0db71e031",
   "metadata": {},
   "source": [
    "To download the data and the model you will need a [HuggingFace](https://huggingface.co) account and [model access](https://huggingface.co/thinkonward/geophysical-foundation-model)\n",
    "\n",
    "<img src=\"src_imgs/model_card.png\" alt=\"huggingface model card\" width=\"800\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70a81f0-866a-4b77-8bd8-619c4d8b997e",
   "metadata": {},
   "source": [
    "After requesting access, you need to [set up an access token](https://huggingface.co/docs/hub/security-tokens) to use the `huggingface_hub` package. Once that is set up, log in by running the next cell and entering your token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e32c6-ce58-4a39-b278-6d416b83233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login, hf_hub_download, snapshot_download\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17653cb-eab4-42f1-85fc-8f4b39ad014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_REPO_ID = \"thinkonward/patch-the-planet\"\n",
    "DATA_FILENAME = \"data/seismicCubes_RFC_fullstack_2023_66442858.parquet\"\n",
    "MODEL_REPO_ID = \"thinkonward/geophysical-foundation-model\"\n",
    "\n",
    "hf_hub_download(\n",
    "    repo_id=DATA_REPO_ID,\n",
    "    filename=DATA_FILENAME,\n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=\"./dataset\",\n",
    ")\n",
    "snapshot_download(repo_id=MODEL_REPO_ID, repo_type=\"model\", local_dir=\"./gfm-weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3ac32b-ef24-40da-8298-4617b423421e",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "Define some functions to convert the seismic volume from parquet to numpy array and mask out a portion we want to interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216dd3d1-9dfd-4885-85ea-9d6a35abab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parquet2array(parquet_file, original_shape=(300, 300, 1259)):\n",
    "    df = pd.read_parquet(parquet_file)\n",
    "    data_only = df.drop(columns=[\"Row\", \"Col\"])\n",
    "    # Convert the DataFrame back to a 2D numpy array\n",
    "    reshaped_array = data_only.values\n",
    "    # Reshape the 2D array back into a 3D array\n",
    "    array = reshaped_array.reshape(original_shape)\n",
    "    return array\n",
    "\n",
    "\n",
    "def mask_image(seismic_slice):\n",
    "    masked_file = seismic_slice.copy()\n",
    "    masked_file[:, 40:110] = 122\n",
    "    mask = np.where(masked_file == 122.0, 1, 0)\n",
    "    return masked_file, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f7af95-36a3-4c9c-b7e8-c037b2d0aa14",
   "metadata": {},
   "source": [
    "Visualize the selected line from the volume and see what the model is going to interpolate and the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9f7d13-d338-41bd-9a4b-a4dfcdf3301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEIS_VOL = parquet2array(\n",
    "    \"./dataset/data/seismicCubes_RFC_fullstack_2023_66442858.parquet\"\n",
    ")\n",
    "SEISMIC_SLICE = SEIS_VOL.T[:, :, 10]\n",
    "MASKED_SLICE, MASK = mask_image(SEISMIC_SLICE)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(6, 6))\n",
    "ax[0].imshow(MASKED_SLICE, cmap=\"gray\")\n",
    "ax[0].set_title(\"Seismic\")\n",
    "ax[1].imshow(MASK, cmap=\"gray\")\n",
    "ax[1].set_title(\"Mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8699a896-066e-4360-a65f-511192994f1d",
   "metadata": {},
   "source": [
    "## Instantiate the model\n",
    "Create an instance of the model architecture, then load the downloaded weights using the `from_pretrained` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8850e9-d72d-4210-aa4e-fb0a8f47ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GFM import ElasticViTMAE\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ElasticViTMAE.ElasticViTMAE()\n",
    "model = model.from_pretrained(\"./gfm-weights\")\n",
    "model = model.float()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0510b15f-733a-4881-901b-55484edc97be",
   "metadata": {},
   "source": [
    "## Do some interpolation\n",
    "Now the fun part!\n",
    "1. resize the seismic slice and mask to the shape for the model to ingest\n",
    "2. get the number of visible patches\n",
    "3. run inference\n",
    "4. combine the prediction and visible portions\n",
    "5. visualize it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a6d211-03b1-488a-80dc-97be059da85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare seismic slice (seismic_slice: 2D slice of volume)\n",
    "resized_slice = st.resize(\n",
    "    MASKED_SLICE.T,\n",
    "    model.patch_embed.img_size[::-1],\n",
    "    order=3,\n",
    "    anti_aliasing=True,\n",
    "    preserve_range=True,\n",
    ")\n",
    "resized_slice = resized_slice.T.astype(np.float32)\n",
    "resized_slice = (resized_slice - SEIS_VOL.mean()) / SEIS_VOL.std()\n",
    "x = torch.tensor(resized_slice)\n",
    "x = x.unsqueeze(0)  # add channel dim\n",
    "x = x.unsqueeze(0)  # add batch dim\n",
    "x = x.float()\n",
    "x = x.to(device)\n",
    "\n",
    "# Prepare mask (target_mask_slice: 2D slice of mask)\n",
    "resized_mask = st.resize(\n",
    "    MASK, model.patch_embed.img_size, order=0, preserve_range=True\n",
    ")\n",
    "mask_idx = np.flatnonzero(resized_mask[0, :])\n",
    "input_mask = np.zeros(model.patch_embed.grid_size)\n",
    "input_mask[:, mask_idx[0] : mask_idx[-1] + 1] = 1\n",
    "input_mask = torch.tensor(input_mask)\n",
    "input_mask = input_mask.float()\n",
    "input_mask = input_mask.to(device)\n",
    "\n",
    "# Prepare length of visible patches\n",
    "len_keep = torch.tensor(int(input_mask.shape[1] - input_mask.sum()))\n",
    "len_keep = len_keep.to(device)\n",
    "\n",
    "# Get interpolated slice\n",
    "loss, pred, mask = model(x, input_mask, len_keep)\n",
    "\n",
    "# Combine prediction and visible part to generate output\n",
    "mask = mask.unsqueeze(-1)\n",
    "visible = model.patchify(x)\n",
    "combined_pred = pred * mask + visible * (1 - mask)\n",
    "combined_pred = model.unpatchify(combined_pred)\n",
    "combined_pred = combined_pred.cpu().detach().numpy()\n",
    "combined_pred = combined_pred.reshape(model.patch_embed.img_size)\n",
    "combined_pred = combined_pred * SEIS_VOL.std() + SEIS_VOL.mean()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.imshow(combined_pred, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36d50be-4e22-4694-ba48-28e90d7c9b17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
